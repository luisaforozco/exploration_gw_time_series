{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0e5b0a6",
   "metadata": {},
   "source": [
    "# Test dataset generation\n",
    "In this notebook we are going to generate a test dataset that is going to serve as ground-truth. The data in this dataset are GLD (Groundwater Level Dossiers) that we have migrated from DINO -> BRO and we are certain that the process was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9278e2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('../../src')\n",
    "from utils_dino import init_connection_to_dino, get_DINO_data_by_piezometer\n",
    "from utils_bro import get_bro_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dce1d4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = init_connection_to_dino()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f5deee",
   "metadata": {},
   "source": [
    "## 1. Get migration id info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ba3c9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_identifiers_migration_GLD_additions = f\"\"\"\n",
    "SELECT\n",
    "  e.BRO_ID,\n",
    "  MIN(w.NITG_NR)          AS NITG_NR,\n",
    "  MIN(w.WELL_DBK)         AS WELL_DBK,\n",
    "  MIN(p.PIEZOMETER_DBK)   AS PIEZOMETER_DBK\n",
    "FROM DINO_DBA.GWS_WELL w\n",
    "INNER JOIN DINO_DBA.GWS_PIEZOMETER p\n",
    "  ON w.WELL_DBK = p.WELL_DBK\n",
    "INNER JOIN DINO_DBA.BRO_MIGRATION_EVENT e\n",
    "  ON p.PIEZOMETER_DBK = e.EVENT_RECORD_DBK\n",
    "WHERE e.RO_TYPE_CD = 'GLD'\n",
    "  AND e.EVENT_TYPE_CD = 'ADDITION'\n",
    "  AND e.TABLE_NM_DBK = (\n",
    "        SELECT TABLE_NM_DBK\n",
    "        FROM DINO_DBA.REF_BRO_MIGRATION_TABLE_NM\n",
    "        WHERE TABLE_NM = 'GWS_PIEZOMETER'\n",
    "      )\n",
    "GROUP BY e.BRO_ID\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a96b023",
   "metadata": {},
   "outputs": [],
   "source": [
    "identifiers_migration_GLD_additions = pd.read_sql(sql_identifiers_migration_GLD_additions, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c08c9c",
   "metadata": {},
   "source": [
    "## 2. Get the data and store it in dicts\n",
    "Here we are skipping data that \n",
    "1. are zombies (`raise ValueError`)\n",
    "2. time-series of different lenghts. \n",
    "    > _Explanation:_ These are the 1-to-many DINO -> BRO cases, something changed in the history of the well/tube making it two separate GMW and thus the time series are stored in different GLD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeeecd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error tokenizing data. C error: Expected 1 fields in line 3, saw 2\n",
      "\n",
      "Er is geen data beschikbaar voor dit dossier GLD000000075026. The response body is empty.\n",
      "Er is geen data beschikbaar voor dit dossier GLD000000078651. The response body is empty.\n",
      "Er is geen data beschikbaar voor dit dossier GLD000000073806. The response body is empty.\n"
     ]
    }
   ],
   "source": [
    "samples = 2_000\n",
    "meta_obs, data_obs = {}, {}\n",
    "# Iterate over all unique BRO_IDs in the identifiers_migration_GLD_additions dataframe (drop_duplicates is redundant here given the sql query but kept for safety)\n",
    "glds_piezo_dbks = identifiers_migration_GLD_additions[['bro_id', 'piezometer_dbk']].drop_duplicates()\n",
    "for i, (gld, piezo_dbk) in enumerate(glds_piezo_dbks.values):\n",
    "    try:\n",
    "        dino_df = get_DINO_data_by_piezometer(piezo_dbk, engine)\n",
    "        bro_df = get_bro_data(gld)\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    if dino_df.shape[0] != bro_df.shape[0]: # data length mismatch\n",
    "        continue\n",
    "    if dino_df.shape[0] < 2 or bro_df.shape[0] < 2: # too few data points\n",
    "        continue\n",
    "    # TODO: decide here what if BRO record has more than 2 columns (multiple observations): \n",
    "    # 1. only take onbekend which is probably the same as DINO and the last in the dataframe (chosen atm, last column)\n",
    "    # 2. store as separate time-series\n",
    "    data_obs[gld] = {'dino': dino_df[['monitor_date', 'value']].values, 'bro': bro_df.iloc[:, [0, -1]].values}\n",
    "    meta_obs[gld] = {'x': dino_df['x'].values[0], 'y': dino_df['y'].values[0], 'NITG_NR': dino_df['nitg_nr'].values[0]}\n",
    "    if i > samples: break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d2251e",
   "metadata": {},
   "source": [
    "## 3. Export the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d77f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(f\"../../data/{len(meta_obs)}_sample_migrated_GLD_dino+bro.pkl\", 'wb') as f:\n",
    "    pickle.dump({'meta': meta_obs, 'data': data_obs}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cd2d04",
   "metadata": {},
   "source": [
    "## 4. Close connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fa56c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.dispose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
